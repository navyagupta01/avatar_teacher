🎓 AI Avatar Teacher
The AI Avatar Teacher is an interactive 3D avatar application designed to act as a virtual teacher. Users can ask questions via text or voice, and the avatar responds using text-to-speech, lip-sync animations, and expressive gestures. Powered by modern web technologies, OpenAI, and Coqui TTS, this project creates an engaging and dynamic learning experience.

🌟 Features
✅ 3D Avatar with Animations
A customizable 3D avatar with lifelike animations and facial expressions (e.g., smile, sad, angry, surprised) using Three.js and React Three Fiber.

✅ Text-to-Speech (TTS)
Converts text responses to speech using Coqui TTS, with audio output in MP3 format.

✅ Lip-Sync
Synchronizes the avatar's lip movements with the generated speech using Rhubarb Lip Sync.

✅ Speech-to-Text
Supports voice input through OpenAI Whisper for transcribing user questions.

✅ Interactive Chat Interface
Users can type or speak questions, and the avatar responds dynamically in real time.

✅ Gesture Support
The avatar performs gestures like TalkingOne, TalkingThree, Idle, and others to enhance expressiveness.

✅ Customizable Models
Uses GLTF models for the avatar and animations, with support for morph targets for facial expressions.

🛠️ Prerequisites
To run this project locally, ensure you have the following installed:

Node.js (v16 or higher)

Python (v3.8 or higher, for Coqui TTS)

FFmpeg (for audio conversion in Rhubarb Lip Sync)

Rhubarb Lip Sync (included in the bin directory or downloadable separately)

Git (for cloning the repository)

🔑 API Keys Required:

OpenAI API: For Whisper (speech-to-text) and ChatGPT (response generation).

